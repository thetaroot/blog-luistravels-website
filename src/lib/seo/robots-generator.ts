/**
 * Enterprise Robots.txt Generator
 * SEO-Dominance-2025 - Advanced robots.txt generation and meta robots optimization
 * Google Senior Dev Level implementation for optimal crawler control
 */

export interface RobotsRule {
  userAgent: string | string[]
  allow?: string[]
  disallow?: string[]
  crawlDelay?: number
  cleanParam?: string[]
}

export interface RobotsConfig {
  sitemap?: string | string[]
  host?: string
  rules: RobotsRule[]
  customDirectives?: Record<string, string>
  environment?: 'production' | 'staging' | 'development'
}

export interface CrawlerConfig {
  name: string
  userAgent: string
  respectsCrawlDelay: boolean
  supportsCleanParam: boolean
  notes?: string
}

export interface MetaRobotsConfig {
  index?: boolean
  follow?: boolean
  noarchive?: boolean
  nosnippet?: boolean
  noimageindex?: boolean
  notranslate?: boolean
  maxSnippet?: number
  maxImagePreview?: 'none' | 'standard' | 'large'
  maxVideoPreview?: number
  unavailableAfter?: string
}

/**
 * Enterprise Robots Generator
 */
export class RobotsGenerator {
  private static instance: RobotsGenerator
  private knownCrawlers: Map<string, CrawlerConfig> = new Map()
  private baseUrl: string = ''

  private constructor() {
    this.initializeKnownCrawlers()
    this.baseUrl = typeof window !== 'undefined' ? window.location.origin : 'https://luis-portfolio.com'
  }

  static getInstance(): RobotsGenerator {
    if (!RobotsGenerator.instance) {
      RobotsGenerator.instance = new RobotsGenerator()
    }
    return RobotsGenerator.instance
  }

  /**
   * Initialize known crawler configurations
   */
  private initializeKnownCrawlers(): void {
    const crawlers: CrawlerConfig[] = [
      {
        name: 'Googlebot',
        userAgent: 'Googlebot',
        respectsCrawlDelay: true,
        supportsCleanParam: true,
        notes: 'Google search crawler'
      },
      {
        name: 'Bingbot',
        userAgent: 'bingbot',
        respectsCrawlDelay: true,
        supportsCleanParam: false,
        notes: 'Microsoft Bing crawler'
      },
      {
        name: 'Slurp',
        userAgent: 'Slurp',
        respectsCrawlDelay: true,
        supportsCleanParam: false,
        notes: 'Yahoo crawler'
      },
      {
        name: 'DuckDuckBot',
        userAgent: 'DuckDuckBot',
        respectsCrawlDelay: true,
        supportsCleanParam: false,
        notes: 'DuckDuckGo crawler'
      },
      {
        name: 'Twitterbot',
        userAgent: 'Twitterbot',
        respectsCrawlDelay: false,
        supportsCleanParam: false,
        notes: 'Twitter card crawler'
      },
      {
        name: 'facebookexternalhit',
        userAgent: 'facebookexternalhit',
        respectsCrawlDelay: false,
        supportsCleanParam: false,
        notes: 'Facebook Open Graph crawler'
      },
      {
        name: 'LinkedInBot',
        userAgent: 'LinkedInBot',
        respectsCrawlDelay: false,
        supportsCleanParam: false,
        notes: 'LinkedIn crawler'
      },
      {
        name: 'WhatsApp',
        userAgent: 'WhatsApp',
        respectsCrawlDelay: false,
        supportsCleanParam: false,
        notes: 'WhatsApp link preview crawler'
      }
    ]

    crawlers.forEach(crawler => {
      this.knownCrawlers.set(crawler.userAgent.toLowerCase(), crawler)
    })
  }

  /**
   * Generate robots.txt content
   */
  generateRobotsTxt(config: RobotsConfig): string {
    const lines: string[] = []

    // Add header comment
    lines.push('# Robots.txt generated by SEO-Dominance-2025 Enterprise System')
    lines.push(`# Generated at: ${new Date().toISOString()}`)
    lines.push('')

    // Environment-specific rules
    if (config.environment === 'production') {
      lines.push('# Production environment - optimized for search engines')
    } else if (config.environment === 'staging') {
      lines.push('# Staging environment - restricted crawling')
    } else if (config.environment === 'development') {
      lines.push('# Development environment - no crawling allowed')
    }
    lines.push('')

    // Add host directive
    if (config.host) {
      lines.push(`Host: ${config.host}`)
      lines.push('')
    }

    // Process rules
    config.rules.forEach(rule => {
      const userAgents = Array.isArray(rule.userAgent) ? rule.userAgent : [rule.userAgent]
      
      userAgents.forEach(userAgent => {
        lines.push(`User-agent: ${userAgent}`)
        
        // Add allow rules
        if (rule.allow && rule.allow.length > 0) {
          rule.allow.forEach(path => {
            lines.push(`Allow: ${path}`)
          })
        }
        
        // Add disallow rules
        if (rule.disallow && rule.disallow.length > 0) {
          rule.disallow.forEach(path => {
            lines.push(`Disallow: ${path}`)
          })
        }
        
        // Add crawl delay
        if (rule.crawlDelay !== undefined) {
          const crawler = this.knownCrawlers.get(userAgent.toLowerCase())
          if (!crawler || crawler.respectsCrawlDelay) {
            lines.push(`Crawl-delay: ${rule.crawlDelay}`)
          }
        }
        
        // Add clean-param (Yandex specific)
        if (rule.cleanParam && rule.cleanParam.length > 0) {
          const crawler = this.knownCrawlers.get(userAgent.toLowerCase())
          if (!crawler || crawler.supportsCleanParam) {
            rule.cleanParam.forEach(param => {
              lines.push(`Clean-param: ${param}`)
            })
          }
        }
        
        lines.push('')
      })
    })

    // Add custom directives
    if (config.customDirectives) {
      Object.entries(config.customDirectives).forEach(([key, value]) => {
        lines.push(`${key}: ${value}`)
      })
      lines.push('')
    }

    // Add sitemap references
    if (config.sitemap) {
      const sitemaps = Array.isArray(config.sitemap) ? config.sitemap : [config.sitemap]
      sitemaps.forEach(sitemap => {
        const sitemapUrl = sitemap.startsWith('http') ? sitemap : `${this.baseUrl}${sitemap}`
        lines.push(`Sitemap: ${sitemapUrl}`)
      })
    }

    return lines.join('\n')
  }

  /**
   * Generate production robots.txt
   */
  generateProductionRobots(): string {
    return this.generateRobotsTxt({
      environment: 'production',
      host: this.baseUrl,
      sitemap: ['/sitemap.xml', '/sitemap-images.xml'],
      rules: [
        // Main search engines
        {
          userAgent: ['Googlebot', 'bingbot', 'Slurp', 'DuckDuckBot'],
          disallow: [
            '/admin/',
            '/api/',
            '/_next/',
            '/404',
            '/500',
            '/*?*utm_*',
            '/*?*fbclid*',
            '/*?*gclid*'
          ],
          allow: [
            '/api/og-image/*',
            '/_next/static/',
            '/_next/image/*'
          ],
          crawlDelay: 1
        },
        
        // Social media crawlers
        {
          userAgent: ['facebookexternalhit', 'Twitterbot', 'LinkedInBot', 'WhatsApp'],
          disallow: ['/admin/', '/api/'],
          allow: [
            '/',
            '/blog/*',
            '/gallery/*',
            '/about',
            '/contact',
            '/api/og-image/*'
          ]
        },
        
        // AI crawlers (be selective)
        {
          userAgent: ['GPTBot', 'ChatGPT-User', 'CCBot', 'anthropic-ai'],
          disallow: ['/']
        },
        
        // Aggressive crawlers
        {
          userAgent: ['SemrushBot', 'AhrefsBot', 'MJ12bot'],
          disallow: ['/'],
          crawlDelay: 10
        },
        
        // All other bots
        {
          userAgent: '*',
          disallow: [
            '/admin/',
            '/api/',
            '/_next/',
            '/404',
            '/500'
          ],
          crawlDelay: 5
        }
      ],
      customDirectives: {
        'Request-rate': '1/5s',
        'Visit-time': '0600-2200'
      }
    })
  }

  /**
   * Generate staging robots.txt
   */
  generateStagingRobots(): string {
    return this.generateRobotsTxt({
      environment: 'staging',
      rules: [
        {
          userAgent: '*',
          disallow: ['/'],
          crawlDelay: 86400 // 24 hours
        }
      ]
    })
  }

  /**
   * Generate development robots.txt
   */
  generateDevelopmentRobots(): string {
    return this.generateRobotsTxt({
      environment: 'development',
      rules: [
        {
          userAgent: '*',
          disallow: ['/']
        }
      ]
    })
  }

  /**
   * Generate meta robots tag content
   */
  generateMetaRobots(config: MetaRobotsConfig): string {
    const directives: string[] = []

    // Index/noindex
    if (config.index === false) {
      directives.push('noindex')
    } else if (config.index === true) {
      directives.push('index')
    }

    // Follow/nofollow
    if (config.follow === false) {
      directives.push('nofollow')
    } else if (config.follow === true) {
      directives.push('follow')
    }

    // Additional directives
    if (config.noarchive) directives.push('noarchive')
    if (config.nosnippet) directives.push('nosnippet')
    if (config.noimageindex) directives.push('noimageindex')
    if (config.notranslate) directives.push('notranslate')

    // Snippet control
    if (config.maxSnippet !== undefined) {
      directives.push(`max-snippet:${config.maxSnippet}`)
    }

    // Image preview control
    if (config.maxImagePreview) {
      directives.push(`max-image-preview:${config.maxImagePreview}`)
    }

    // Video preview control
    if (config.maxVideoPreview !== undefined) {
      directives.push(`max-video-preview:${config.maxVideoPreview}`)
    }

    // Unavailable after
    if (config.unavailableAfter) {
      directives.push(`unavailable_after:${config.unavailableAfter}`)
    }

    return directives.join(', ')
  }

  /**
   * Generate page-specific meta robots
   */
  generatePageMetaRobots(pageType: string, isPublished: boolean = true): string {
    const configs: Record<string, MetaRobotsConfig> = {
      'home': {
        index: true,
        follow: true,
        maxSnippet: -1,
        maxImagePreview: 'large',
        maxVideoPreview: -1
      },
      'blog-post': {
        index: isPublished,
        follow: true,
        maxSnippet: 200,
        maxImagePreview: 'large',
        maxVideoPreview: 30
      },
      'blog-list': {
        index: true,
        follow: true,
        maxSnippet: 150,
        maxImagePreview: 'standard'
      },
      'gallery': {
        index: true,
        follow: true,
        maxSnippet: 100,
        maxImagePreview: 'large',
        noimageindex: false
      },
      'contact': {
        index: true,
        follow: false,
        maxSnippet: 100,
        maxImagePreview: 'standard'
      },
      'about': {
        index: true,
        follow: true,
        maxSnippet: -1,
        maxImagePreview: 'large'
      },
      '404': {
        index: false,
        follow: false,
        noarchive: true,
        nosnippet: true
      },
      'admin': {
        index: false,
        follow: false,
        noarchive: true,
        nosnippet: true
      }
    }

    const config = configs[pageType] || configs['home']
    return this.generateMetaRobots(config)
  }

  /**
   * Validate robots.txt content
   */
  validateRobotsTxt(content: string): Array<{
    line: number
    issue: string
    severity: 'error' | 'warning'
    suggestion: string
  }> {
    const issues = []
    const lines = content.split('\n')

    for (let i = 0; i < lines.length; i++) {
      const line = lines[i].trim()
      const lineNumber = i + 1

      if (line.startsWith('#') || line === '') continue

      // Check for valid directives
      const colonIndex = line.indexOf(':')
      if (colonIndex === -1) {
        issues.push({
          line: lineNumber,
          issue: 'Invalid directive format - missing colon',
          severity: 'error' as const,
          suggestion: 'Use format "Directive: value"'
        })
        continue
      }

      const directive = line.substring(0, colonIndex).trim().toLowerCase()
      const value = line.substring(colonIndex + 1).trim()

      // Validate common directives
      switch (directive) {
        case 'user-agent':
          if (!value) {
            issues.push({
              line: lineNumber,
              issue: 'Empty user-agent value',
              severity: 'error' as const,
              suggestion: 'Specify a user-agent or use "*" for all'
            })
          }
          break

        case 'disallow':
        case 'allow':
          if (value && !value.startsWith('/')) {
            issues.push({
              line: lineNumber,
              issue: `${directive} path should start with "/"`,
              severity: 'warning' as const,
              suggestion: `Use "/${value}" instead of "${value}"`
            })
          }
          break

        case 'crawl-delay':
          const delay = parseInt(value)
          if (isNaN(delay) || delay < 0) {
            issues.push({
              line: lineNumber,
              issue: 'Invalid crawl-delay value',
              severity: 'error' as const,
              suggestion: 'Use a positive integer for crawl delay in seconds'
            })
          } else if (delay > 3600) {
            issues.push({
              line: lineNumber,
              issue: 'Very high crawl delay',
              severity: 'warning' as const,
              suggestion: 'Consider using a lower value to allow reasonable crawling'
            })
          }
          break

        case 'sitemap':
          try {
            new URL(value)
          } catch {
            if (!value.startsWith('/')) {
              issues.push({
                line: lineNumber,
                issue: 'Invalid sitemap URL',
                severity: 'error' as const,
                suggestion: 'Use absolute URL or path starting with "/"'
              })
            }
          }
          break
      }
    }

    return issues
  }

  /**
   * Generate robots.txt for different environments
   */
  generateEnvironmentRobots(environment: 'production' | 'staging' | 'development'): string {
    switch (environment) {
      case 'production':
        return this.generateProductionRobots()
      case 'staging':
        return this.generateStagingRobots()
      case 'development':
        return this.generateDevelopmentRobots()
      default:
        return this.generateProductionRobots()
    }
  }

  /**
   * Get crawler statistics
   */
  getCrawlerStats(): {
    knownCrawlers: number
    searchEngineCrawlers: number
    socialMediaCrawlers: number
    aiCrawlers: number
  } {
    const crawlers = Array.from(this.knownCrawlers.values())
    
    return {
      knownCrawlers: crawlers.length,
      searchEngineCrawlers: crawlers.filter(c => 
        ['googlebot', 'bingbot', 'slurp', 'duckduckbot'].includes(c.userAgent.toLowerCase())
      ).length,
      socialMediaCrawlers: crawlers.filter(c => 
        ['facebookexternalhit', 'twitterbot', 'linkedinbot', 'whatsapp'].includes(c.userAgent.toLowerCase())
      ).length,
      aiCrawlers: crawlers.filter(c => 
        c.userAgent.toLowerCase().includes('gpt') || 
        c.userAgent.toLowerCase().includes('ai') ||
        c.userAgent.toLowerCase().includes('bot')
      ).length
    }
  }
}

export default RobotsGenerator